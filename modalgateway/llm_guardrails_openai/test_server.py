"""
Test script for OpenAI LLM Backend
Validates guardrails and response quality
"""

import requests
import json

BASE_URL = "http://localhost:8036"

def test_health():
    """Test health endpoint"""
    print("\n" + "=" * 60)
    print("Testing Health Endpoint")
    print("=" * 60)
    
    response = requests.get(f"{BASE_URL}/health")
    print(f"Status: {response.status_code}")
    print(f"Response: {json.dumps(response.json(), indent=2)}")

def test_allowed_query():
    """Test an allowed workplace query"""
    print("\n" + "=" * 60)
    print("Testing ALLOWED Query (HR Template)")
    print("=" * 60)
    
    payload = {
        "query": "Can you help me draft a professional leave request email for sick leave?",
        "persona": "hr"
    }
    
    response = requests.post(f"{BASE_URL}/api/llm/query", json=payload)
    result = response.json()
    
    print(f"Status: {response.status_code}")
    print(f"Answer: {result['answer'][:200]}...")
    print(f"Tokens: {result['tokens_used']}")
    print(f"Model: {result['model']}")

def test_forbidden_query():
    """Test a forbidden query (should be refused)"""
    print("\n" + "=" * 60)
    print("Testing FORBIDDEN Query (General Knowledge)")
    print("=" * 60)
    
    payload = {
        "query": "What's the weather like today?",
        "persona": "hr"
    }
    
    response = requests.post(f"{BASE_URL}/api/llm/query", json=payload)
    result = response.json()
    
    print(f"Status: {response.status_code}")
    print(f"Answer: {result['answer']}")
    print(f"Tokens: {result['tokens_used']}")
    
    # Check if it refused
    if "cannot" in result['answer'].lower() or "not able" in result['answer'].lower():
        print("\n‚úÖ PASS: Query was correctly refused")
    else:
        print("\n‚ùå FAIL: Query should have been refused")

def test_executive_persona():
    """Test executive persona"""
    print("\n" + "=" * 60)
    print("Testing Executive Persona")
    print("=" * 60)
    
    payload = {
        "query": "Help me draft an executive summary for our Q4 performance review.",
        "persona": "executive",
        "temperature": 0.3
    }
    
    response = requests.post(f"{BASE_URL}/api/llm/query", json=payload)
    result = response.json()
    
    print(f"Status: {response.status_code}")
    print(f"Answer: {result['answer'][:300]}...")
    print(f"Tokens: {result['tokens_used']}")

def test_guardrails_validation():
    """Test the guardrails test endpoint"""
    print("\n" + "=" * 60)
    print("Testing Guardrails Validation Endpoint")
    print("=" * 60)
    
    test_cases = [
        {
            "query": "Draft a leave request email",
            "expected": "allowed"
        },
        {
            "query": "What's the latest news?",
            "expected": "refused"
        },
        {
            "query": "Help me write a project status update",
            "expected": "allowed"
        }
    ]
    
    for i, test_case in enumerate(test_cases, 1):
        print(f"\nTest Case {i}: {test_case['query']}")
        
        payload = {"query": test_case["query"]}
        response = requests.post(f"{BASE_URL}/api/llm/test", json=payload)
        result = response.json()
        
        print(f"  Should Refuse: {result['should_refuse']}")
        print(f"  Test Passed: {result['test_passed']}")
        print(f"  Answer Preview: {result['answer'][:100]}...")

if __name__ == "__main__":
    print("\nüöÄ OpenAI LLM Backend Test Suite")
    print("=" * 60)
    
    try:
        test_health()
        test_allowed_query()
        test_forbidden_query()
        test_executive_persona()
        test_guardrails_validation()
        
        print("\n" + "=" * 60)
        print("‚úÖ All tests completed!")
        print("=" * 60)
    
    except requests.exceptions.ConnectionError:
        print("\n‚ùå ERROR: Cannot connect to server")
        print("Make sure the server is running: python server.py")
    except Exception as e:
        print(f"\n‚ùå ERROR: {e}")
